## simpler than testing inclusion in a set.
## read.csv() will be faster if you specify known column types with
## colClasses.
## see p. 361-364 of Advanced R for an example of how you can modify
## existing base R functions to speed them up for very specific needs
### 2. Vectorizing
### The key idea behind vectorizing your code is to think about entire
### vectors instead of thinking about their components. Using apply and co
### instead of for loops is a start, but does not really solve this issue.
### Truly vectorized functions will make use of code written in C instead
### of R. Loops in C are much faster because they have much less overhead.
## Examples
## Addition on each element of a data frame
rm(list=ls())
m=5
n=5
matrix1 <- replicate(m, rnorm(n)) # create matrix
matdf <- matdf1 <- matdf2 <- data.frame(matrix1) # transform into data frame
matdf
for (i in 1:m) {
for (j in 1:n) {
matdf1[i,j] <- matdf1[i,j] + 1.87*cos(.25)*pi # addition
}
}
matdf1
matdf2 <- matdf2 + 1.87*cos(.25)*pi
matdf2
microbenchmark(
"loop" = for (i in 1:m) {
for (j in 1:n) {
matdf[i,j] <- matdf[i,j] + 1.87*cos(.25)*pi
}
},
"vectorized" = matdf <- matdf + 1.87*cos(.25)*pi
)
## rowSums / colSums
mat1 <- matrix(abs(rnorm(2500))+pi, ncol=50)
head(mat1)[,1:5]
apply(mat1, 1, function(x) sum(x))
rowSums(mat1)
microbenchmark(apply(mat1, 1, function(x) sum(x)),
rowSums(mat1))
## rowMeans/colMeans
apply(mat1, 2, function(x) mean(x))
colMeans(mat1)
microbenchmark(apply(mat1, 2, function(x) mean(x)),
colMeans(mat1))
## Even when working with matrices, think about the actual
## calculations you perform
mat2 <- matrix(sample(1:7, 90000, replace=T), ncol=300)
mat3 <- matrix(sample(2:6, 90000, replace=T), ncol=300)
ys <- sample(3:5, 300, replace=T)
all.equal(mat2 %*% mat3 %*% ys , mat2 %*% (mat3 %*% ys))
microbenchmark(mat2 %*% mat3 %*% ys,
mat2 %*% (mat3 %*% ys))
## Crossproducts
mat4 <- matrix(1:4, ncol=2)
mat5 <- matrix(5:8, ncol=2)
microbenchmark(t(mat4)%*%mat5,
crossprod(mat4, mat5))
## Paste/collapse and copies
random_states <- function() {
paste(sample(state.name,10,replace =TRUE),collapse ="")
}
states10 <- replicate(10, random_states())
states10
states100 <- replicate(100, random_states())
collapse <- function(states) {
out <- ""
for (x in states) {
out <- paste0(out, x) # same as paste(..., sep="", collapse)
}
out
}
microbenchmark(
"loop10" = collapse(states10),
"vec10" = paste(states10, collapse =""),
"loop100" = collapse(states100),
"vec100" = paste(states100, collapse ="")
)
## Here, we are not only getting around using the loop, but also
## avoiding copies. Whenever you append(), cbind(), rbind(), or
## paste() to create a bigger object, R must first allocate space
## for the new object and then copy the old object to its new home.
## If you're repeating this many times, like in a for loop, this
## can be quite computationally expensive.
## Parallelization
## Parallelization uses multiple cores to work simultaneously on different
## parts of a problem. It doesn't reduce the computing time, but it saves
## your time because you're using more of your computer's resources.
install.packages("parallel")
library(parallel)
cores <- detectCores()
cores
pause <- function(i) {
function(x) Sys.sleep(i)
}
## On a Mac:
microbenchmark(
lapply(1:4, pause(0.25)),
mclapply(1:4, pause(0.25), mc.cores = cores),
times=10
)
## On a Windows machine:
cluster <- makePSOCKcluster(cores)
microbenchmark(
parLapply(cluster, 1:4, pause(0.25)),
lapply(1:4, pause(0.25)),
times=10
)
## More generally with apply/plyr family
library(plyr)
bigmat <- matrix(rnorm(90000), ncol=300)
dim(bigmat)
## Mac:
install.packages("doMC")
library(doMC)
registerDoMC(3) # register number of cores
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
times=20
)
## But of course we now know that this should really be colSums
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
"vectorized" = colSums(bigmat),
times=20
)
## Windows:
install.packages("foreach")
library(foreach)
install.packages("doSNOW")
library(doSNOW)
registerDoSNOW(makeCluster(2, type = "SOCK")) # set to two cores
getDoParWorkers() # check number of cores
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
times=20
)
## But of course we now know that this should really be colSums
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
"vectorized" = colSums(bigmat),
times=20
)
install.packages("microbenchmark")
install.packages("doSNOW")
install.packages("foreach")
install.packages("doSNOW")
install.packages("foreach")
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
"vectorized" = colSums(bigmat),
times=20
)
warnings()
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
"vectorized" = colSums(bigmat),
times=20
)
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"vectorized" = colSums(bigmat),
times=20
)
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum),
"vectorized" = colSums(bigmat),
times=20
)
install.packages("foreach")
library(foreach)
install.packages("foreach")
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum),
"vectorized" = colSums(bigmat),
times=20
)
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
"vectorized" = colSums(bigmat),
times=20
)
library(foreach)
library(doSNOW)
registerDoSNOW(makeCluster(2, type = "SOCK")) # set to two cores
getDoParWorkers() # check number of cores
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
times=20
)
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
"vectorized" = colSums(bigmat),
times=20
)
warnings()
library(microbenchmark)
microbenchmark(sqrt(x),
x^0.5,
times=1000)
head(mtcars)
microbenchmark(
"[32, 11]" = mtcars[32,11],
"$carb[32]"	= mtcars$carb[32],
"[[c(11, 32)]]" = mtcars[[c(11,32)]],
"[[11]][32]" = mtcars[[11]][32],
".subset2" = .subset2(mtcars,11)[32])
library(profvis)
m=5
n=5
matrix1 <- replicate(m, rnorm(n)) # create matrix
matdf <- matdf1 <- matdf2 <- data.frame(matrix1) # transform into data frame
matdf
for (i in 1:m) {
for (j in 1:n) {
matdf1[i,j] <- matdf1[i,j] + 1.87*cos(.25)*pi # addition
}
}
matdf1
matdf2 <- matdf2 + 1.87*cos(.25)*pi
matdf2
microbenchmark(
"loop" = for (i in 1:m) {
for (j in 1:n) {
matdf[i,j] <- matdf[i,j] + 1.87*cos(.25)*pi
}
},
"vectorized" = matdf <- matdf + 1.87*cos(.25)*pi
)
mat1 <- matrix(abs(rnorm(2500))+pi, ncol=50)
head(mat1)[,1:5]
apply(mat1, 1, function(x) sum(x))
rowSums(mat1)
microbenchmark(apply(mat1, 1, function(x) sum(x)),
rowSums(mat1))
apply(mat1, 2, function(x) mean(x))
colMeans(mat1)
microbenchmark(apply(mat1, 2, function(x) mean(x)),
colMeans(mat1))
mat2 <- matrix(sample(1:7, 90000, replace=T), ncol=300)
mat3 <- matrix(sample(2:6, 90000, replace=T), ncol=300)
ys <- sample(3:5, 300, replace=T)
all.equal(mat2 %*% mat3 %*% ys , mat2 %*% (mat3 %*% ys))
microbenchmark(mat2 %*% mat3 %*% ys,
mat2 %*% (mat3 %*% ys))
mat4 <- matrix(1:4, ncol=2)
mat5 <- matrix(5:8, ncol=2)
microbenchmark(t(mat4)%*%mat5,
crossprod(mat4, mat5))
random_states <- function() {
paste(sample(state.name,10,replace =TRUE),collapse ="")
}
states10 <- replicate(10, random_states())
states10
states100 <- replicate(100, random_states())
collapse <- function(states) {
out <- ""
for (x in states) {
out <- paste0(out, x) # same as paste(..., sep="", collapse)
}
out
}
microbenchmark(
"loop10" = collapse(states10),
"vec10" = paste(states10, collapse =""),
"loop100" = collapse(states100),
"vec100" = paste(states100, collapse ="")
)
library(parallel)
cores <- detectCores()
cores
pause <- function(i) {
function(x) Sys.sleep(i)
}
cluster <- makePSOCKcluster(cores)
microbenchmark(
parLapply(cluster, 1:4, pause(0.25)),
lapply(1:4, pause(0.25)),
times=10
)
library(plyr)
bigmat <- matrix(rnorm(90000), ncol=300)
dim(bigmat)
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
"vectorized" = colSums(bigmat),
times=20
)
library(foreach)
library(foreach)
library(doSNOW)
registerDoSNOW(makeCluster(2, type = "SOCK")) # set to two cores
getDoParWorkers() # check number of cores
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
times=20
)
library(readr)
Multiple_Cause_of_Death_1999_2016 <- read_csv("~/Opioid Public Policy Project/Multiple Cause of Death, 1999-2016.txt")
View(Multiple_Cause_of_Death_1999_2016)
View(Multiple_Cause_of_Death_1999_2016)
setwd("~/GitHub/Project")
load("~/GitHub/Project/PredsWorkspace.RData")
View(preds)
regress.func <- function(Y, preds.var){
# need to smartly figure out which columns are not NA
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
library(quadprog)
d.mat <- solve(chol(t(predX)%*%predX))
a.mat <- cbind(rep(1, ncol(predX)), diag(ncol(predX)))
b.vec <- c(1, rep(0, ncol(predX)))
d.vec <- t(Y) %*% predX
out<- solve.QP(Dmat = d.mat, factorized =TRUE, dvec = d.vec, Amat = a.mat, bvec = b.vec, meq = 1)
coefs <- rep(NA, orgcols)
notDel <- c(1:orgcols)[notNA]#[notCor]
coefs[notDel] <- out$solution
return(coefs)
}
regress.func(Y, preds)
regress.func(Y, preds)
preds.var <- preds
preds.var <- preds
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
library(quadprog)
d.mat <- solve(chol(t(predX)%*%predX))
?chol.default
t(predX)
t(predX)%*%predX)
t(predX)%*%predX
preds.var <- as.list(preds)
regress.func(Y, preds.var)
preds.var
preds.var <- as.vector(preds)
regress.func(Y, preds.var)
orgcols <- length(preds.var[1,])
orgcols <- length(preds.var[1,])
View(preds)
preds.var <- preds
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
d.mat <- solve(chol(t(predX)%*%predX))
d.mat <- solve(chol(predX%*%predX))
fold <- sample(10, nrow(X), replace = T)
sort(unique(fold))
ish <- list()
ish[[1]] <- preds.in.order[1:106,]
ish
1080/10
data.listed[[1]] <- preds.in.order[1:108,]
data.listed <- list()
data.listed[[1]] <- preds.in.order[1:108,]
data.listed[[2]] <- preds.in.order[108:217,]
View(preds)
View(preds.in.order)
data.listed[[1]] <- preds.in.order[1:107,]
data.listed[[2]] <- preds.in.order[108:215,]
data.listed[[3]] <- preds.in.order[216:323,]
data.listed[[4]] <- preds.in.order[324:431,]
data.listed[[5]] <- preds.in.order[432:539,]
data.listed[[6]] <- preds.in.order[540:647,]
data.listed[[7]] <- preds.in.order[648:755,]
data.listed[[8]] <- preds.in.order[756:863,]
data.listed[[9]] <- preds.in.order[864:971,]
data.listed[[10]] <- preds.in.order[972:1074,]
regress.func(Y, data.listed)
regress.func(Y, data.listed)
preds.var <- data.listed
length(preds.var[1,])
preds.var <- matrix(NA, nrow=nrow(X),ncol=12)
View(preds)
View(preds.in.order)
regress.func(Y, preds)
preds.var <- preds
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
t(predX)%*%predX
predX
View(predX)
preds.var[1,]
preds.var[,1]
orgcols <- length(preds.var[2,])
notNA <- which(!is.na(preds.var[2,]))
predX <- preds.var[,notNA ]
View(predX)
t(predX)%*%predX
d.mat <- solve(chol(t(predX)%*%predX))
preds.var <- preds.in.order
orgcols <- length(preds.var[2,])
notNA <- which(!is.na(preds.var[2,]))
predX <- preds.var[,notNA ]
View(predX)
t(predX)%*%predX
chol(t(predX)%*%predX)
whatshappening preds.var[1,]
whatshappening <- preds.var[1,]
whatshappening
preds
m<- as.matrix(preds.in.order)
mm<- matrix(m, ncol = ncol(preds.in.order), dimnames = NULL)
View(mm)
preds.var <-mm
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
View(predX)
d.mat <- solve(chol(t(predX)%*%predX))
t(predX)%*%predX
View(predX)
predX <-predX[1:1080,]
View(predX)
predX <-predX[1:1080,]
t(predX)%*%predX
solve(chol(t(predX)%*%predX))
cbind(rep(1, ncol(predX)), diag(ncol(predX)))
regress.func <- function(Y, preds.var){
# need to smartly figure out which columns are not NA
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
predX <-predX[1:1080,]
library(quadprog)
d.mat <- solve(chol(t(predX)%*%predX))
a.mat <- cbind(rep(1, ncol(predX)), diag(ncol(predX)))
b.vec <- c(1, rep(0, ncol(predX)))
d.vec <- t(Y) %*% predX
out<- solve.QP(Dmat = d.mat, factorized =TRUE, dvec = d.vec, Amat = a.mat, bvec = b.vec, meq = 1)
coefs <- rep(NA, orgcols)
notDel <- c(1:orgcols)[notNA]#[notCor]
coefs[notDel] <- out$solution
return(coefs)
}
regress.func(Y, preds.var)
d.mat <- solve(chol(t(predX)%*%predX))
a.mat <- cbind(rep(1, ncol(predX)), diag(ncol(predX)))
b.vec <- c(1, rep(0, ncol(predX)))
d.vec <- t(Y) %*% predX
Y
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
predX <-predX[1:1074,]
d.mat <- solve(chol(t(predX)%*%predX))
a.mat <- cbind(rep(1, ncol(predX)), diag(ncol(predX)))
b.vec <- c(1, rep(0, ncol(predX)))
d.vec <- t(Y) %*% predX #doesn't like diff number of rows
out<- solve.QP(Dmat = d.mat, factorized =TRUE, dvec = d.vec, Amat = a.mat, bvec = b.vec, meq = 1)
coefs <- rep(NA, orgcols)
notDel <- c(1:orgcols)[notNA]#[notCor]
coefs[notDel] <- out$solution
regress.func <- function(Y, preds.var){
# need to smartly figure out which columns are not NA
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
predX <-predX[1:1074,]
library(quadprog)
d.mat <- solve(chol(t(predX)%*%predX))
a.mat <- cbind(rep(1, ncol(predX)), diag(ncol(predX)))
b.vec <- c(1, rep(0, ncol(predX)))
d.vec <- t(Y) %*% predX #doesn't like diff number of rows
out<- solve.QP(Dmat = d.mat, factorized =TRUE, dvec = d.vec, Amat = a.mat, bvec = b.vec, meq = 1)
coefs <- rep(NA, orgcols)
notDel <- c(1:orgcols)[notNA]#[notCor]
coefs[notDel] <- out$solution
return(coefs)
}
regress.func(Y, preds.var)
preds.var <- preds.in.order
regress.func <- function(Y, preds.var){
# need to smartly figure out which columns are not NA
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
predX <-predX[1:1074,]
library(quadprog)
d.mat <- solve(chol(t(predX)%*%predX))
a.mat <- cbind(rep(1, ncol(predX)), diag(ncol(predX)))
b.vec <- c(1, rep(0, ncol(predX)))
d.vec <- t(Y) %*% predX #doesn't like diff number of rows
out<- solve.QP(Dmat = d.mat, factorized =TRUE, dvec = d.vec, Amat = a.mat, bvec = b.vec, meq = 1)
coefs <- rep(NA, orgcols)
notDel <- c(1:orgcols)[notNA]#[notCor]
coefs[notDel] <- out$solution
return(coefs)
}
regress.func(Y, preds.var)
regress.func(Y, preds.in.order)
View(preds.in.order)
